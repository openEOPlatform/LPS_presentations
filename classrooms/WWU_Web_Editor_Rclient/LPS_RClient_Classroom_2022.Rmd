---
title: "Living Planet Symposiom 2022: openEO platform R-Client Classroom"
author: 
 - Peter Zellner, Eurac Research
 - Florian Lahn, EFTAS
 - Matthias Mohr, University of Münster
 - Mattia Rossi, Eurac Research
date: "11/05/2022"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: TRUE
---

![](https://webassets.eurac.edu/31538/1629894586-open-eo-platform.png?fit=max&fm=jpg&w=1000){width="400"}

![](https://www.eurac.edu/_next/image?url=https%253A%252F%252Fwebassets.eurac.edu%252F31538%252F1634027841-logoproject.png%253Fauto%253Dformat%2526fit%253Dclip%2526fm%253Djpg%2526h%253D300%2526w%253D300&w=640&q=85){width="116"}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Preface

## Before you start...

-   the openEO platform getting started guide <https://docs.openeo.cloud/getting-started/r/>
-   the openEO R-Client vignettes <https://open-eo.github.io/openeo-r-client/>
-   and the R-Client repo for logging issues and collaborating <https://github.com/Open-EO/openeo-r-client>
-   Introduction to data-cubes <https://openeo.org/documentation/1.0/datacubes.html>

## Topics

-   Installation of the openEO R-Client
-   Authentication and Log-In
-   Discovery of collections and processes
-   Usability and R-Studio integration
-   Processing
-   Analyze results

# Installation of the openEO R-Client

The openEO R-Client is available on CRAN. Install via `install.packages("openeo")`.

In case you want to use a specific version of the R-Client you can install it from the [openEO github repository](https://github.com/Open-EO/openeo-r-client).

It can be installed via `remotes::install_github()`. For the dev version set `remotes::install_github(repo="Open-EO/openeo-r-client",ref="develop", dependencies=TRUE)`.

```{r install, eval=FALSE}
# install.packages("openeo")
packageVersion("openeo") >= '1.2.0'
```

## Useful libraries

Load the openEO R-Client library and some other useful libraries.

```{r libs, message=FALSE, warning=FALSE}
library(openeo)
library(stars)
library(sf)
library(mapview)
library(mapedit)
library(dplyr)
library(tibble)
library(ggplot2)
library(plotly)
```

# Authentication and Login

## Authentication

Before you can use openEO Platform you need a user account to authenticate yourself. To handle authentication, openEO leverages [OpenID Connect (OIDC)](https://openid.net/connect/). The [general authentication documentation for openEO Platform](https://docs.openeo.cloud/authentication/#authentication) describes the authentication procedure in more detail.

## Login

First connect to the backend. This allows to discover the collections (as seen in the connections pane) and the processes.

In a second step log in. This allows to use the full functionality of openEO Platform including processing. Slight differences will occur depending on the type of account you have (e.g., free tier, early adopter).

```{r connect_and_login}
host = "https://openeo.cloud"
con = openeo::connect(host)
login()
```

Sometimes it's useful to get your account information and check whether you are still logged in.

```{r check_login}
describe_account()
con$isConnected()
con$isLoggedIn()
```

# Discovery of collections and processes

Once you're connected you can discover processes and collections. This gives you valuable metadata on collections and information on how to use the processes.

## Discover collections

The collections appear in the connections pane of R-Studio. You can also list them via `list_collections()` directly:

```{r list_collections}
list_collections()
```

For the full metadata of a single collection, use `describe_collection()`.

```{r describe_collection}
coll_meta = openeo::describe_collection("SENTINEL2_L1C_SENTINELHUB")
coll_meta
```

To use the collection metadata for further coding you can use the content of `describe_collection()`.

```{r describe_collection}
ext = coll_meta$extent$spatial # you could use this to draw a bbox of the collection
st_bbox(obj = c(xmin = ext[1], ymin = ext[2], xmax = ext[3], ymax = ext[4]), crs = 4326) %>% mapview()
```

## Discover processes

To get an overview of the available processes use `list_processes()`

```{r list_processes}
list_processes()
```

# Processing

-   Load Sentinel 2 L1C data
-   Define the area of interest, temporal range and bands
-   Atmospherically correct the values on the fly
-   Aggregate monthly means
-   Calculate the NDVI
-   Download the result

## Definitions

First define an area of interest interactively (either a point or area). You can also use multiple features and loop through them later on.

```{r aoi_process}
# this is interactive
pnts = mapedit::drawFeatures()

# this is static for areas - Bonn
# pnts = c(xmin = 6.631536, ymin = 50.811346, xmax = 6.646557, ymax = 50.821710)
# pnts = st_bbox(pnts, crs = st_crs(4326))
mapview(pnts)
```

```{r def_bbox}
bbox = st_bbox(pnts)
bbox = list(west = bbox[[1]],
            east = bbox[[3]],
            south = bbox[[2]],
            north = bbox[[4]])
```

Define the collection (data set), time range and bands.

```{r defs_process}

collection = "SENTINEL2_L2A"
bands = c("B04", "B08")
time_range = list("2018-01-01", 
                  "2019-01-01")

# The extensive list of bands is only needed if atmospheric correction is applied.
# collection = "SENTINEL2_L1C_SENTINELHUB" # for atmospheric_correction, takes a while
# bands = c("B04", "B08", "CLP", "B09", "B8A", "B11",
#           "sunAzimuthAngles", "sunZenithAngles", "viewAzimuthMean", "viewZenithMean")


```

## Build the processing chain

Start building the processing chain. First, load the available processes. You can access the available processes assigned to `p` here via the `$` operator.

⚠️ Auto-completion is a very helpful feature ⚠️

```{r load_processes, eval=FALSE}
p = processes()
```

Load the collection.

```{r load_data, eval=FALSE}
data = p$load_collection(id = collection, 
                         spatial_extent = bbox,
                         temporal_extent = time_range, 
                         bands = bands) 
#, properties = list("eo:cloud_cover" = function(x){x < 35})) # for the whole scene, not the aoi
# The different processes can be also chained using the pipe %>%.
  
```

Atmospherical Correction on the fly. Only works for collections that support/need atmospheric correction (e.g., "SENTINEL2_L1C_SENTINELHUB) and the necessary bands need to be available in the data cube (see extended band list above).

```{r atmopspherical_correction, eval=FALSE}
# takes too long, for the demo since has to work on whole tile
# atm_corr = p$atmospheric_correction(data = data, method = "smac") # or use "iCor"
```

Calculate NDVI. Reduce the "bands" dimension with the well known NDVI formula.

```{r calc_ndvi, eval=FALSE}
calc_ndvi = p$reduce_dimension(data = data, 
                               dimension = "bands", 
                               reducer = function(data, context) {
                                 red = data[1]
                                 nir = data[2]
                                 (nir-red)/(nir+red)})

```

Aggregate to user defined temporal periods.

```{r temporal_period, eval=FALSE}
# process_viewer("aggregate_temporal")

# define intervals
intervals = list(c('2018-01-02', '2018-02-01'),
                 c('2018-02-01', '2018-03-01'),
                 c('2018-03-01', '2018-04-01'),
                 c('2018-04-01', '2018-05-01'),
                 c('2018-05-01', '2018-06-01'), 
                 c('2018-06-01', '2018-07-01'), 
                 c('2018-07-01', '2018-08-01'),
                 c('2018-08-01', '2018-09-01'),
                 c('2018-09-01', '2018-10-01'), 
                 c('2018-10-01', '2018-11-01'),
                 c('2018-11-01', '2018-12-01'), 
                 c('2018-12-01', '2018-12-30'))
# and labels
labels = lapply(intervals, function(x){x[[1]]}) %>% unlist() # create labels from list

# add the process node
temp_period = p$aggregate_temporal(data = calc_ndvi,
                                   intervals = intervals,
                                   reducer = function(data, context){p$median(data)},
                                   labels = labels,
                                   dimension = "t")
```

Alternatively use `aggregate_temporal_period()`and select a period.

```{r temporal_period2, eval=FALSE}
# temp_period = p$aggregate_temporal_period(data = calc_ndvi, 
#                                           period = "month", 
#                                           reducer = function(data, context){p$median(data)}, dimension = "t")


```

Alternatively, for receiving only one time slice, calculate the yearly mean.

```{r temporal_mean, eval=FALSE}
# temp_period = p$reduce_dimension(data = calc_ndvi,
#                                  reducer = function(data, context){p$mean(data)},
#                                  dimension = "t")
```

Save the result.

```{r save_result, eval=FALSE}
result = p$save_result(data = temp_period, format="NetCDF")
```

No processing has happened so far. Only the workflow/process graph has been defined.

```{r vis_graph, eval=FALSE}
#toJSON(as(result, "Process"))
#process_viewer(as(result, "Process"))
as(result, "Process")
```

## Compute the result

synchronous call (result is computed directly, currently times out after 5 mins)

```{r out_name}
out_name =  "r_ndvi_classroom_lps.nc"
```

```{r compute_result, eval=FALSE}
a = Sys.time()
compute_result(result,
               output_file = out_name, 
               con = con)
b = Sys.time()-a
b
```

# Analyze Results

## Load Results

```{r load_result}
# load the data into r
ndvi = read_stars(out_name)

# check which projection your data has and assign it, in case not automatically done
#system(paste0("gdalinfo ", out_name))
#st_crs(ndvi) = st_crs(32632)

# look at the time dimension
stars::st_get_dimension_values(ndvi, "t") %>% as_tibble()
```

## Plot 

plot some time slices (select and deselect in the viewer)

```{r plot_area}
brks = seq(-0, 1, 0.1)
mapview(ndvi %>% slice("t", 3), at = brks) + 
  mapview(ndvi %>% slice("t", 5), at = brks) + 
  mapview(ndvi %>% slice("t", 7), at = brks) +
  mapview(ndvi %>% slice("t", 9), at = brks) + 
  mapview(pnts)
```

## Timeseries 

Get a point for plotting a pixel timeseries

```{r get_pixel}
# define a point
pixel = mapedit::drawFeatures(mapview(pnts))
# pixel = st_centroid(st_as_sf(st_as_sfc(pnts)))

# static assignment
# pixel = data.frame(x = 6.635957, y = 50.8165)
# pixel = st_as_sf(pixel, coords = c("x", "y"), crs = st_crs(4326))

mapview(pixel) + mapview(pnts) + mapview(st_bbox(ndvi))
```

subset existing result to a point and plot a pixel time series

```{r plot_ts}
# subset to point
pixel = st_transform(x = pixel, crs = st_crs(ndvi))
ndvi_ts = ndvi[pixel]

# generate a data frame from the values and dates
ndvi_ts_df = data.frame(value = ndvi_ts %>% pull() %>% c() %>% as.vector(), 
                        dates = as.Date(st_get_dimension_values(ndvi_ts, "t")))

# plot the timeseries
plot_ts = ggplot(ndvi_ts_df, aes(x = dates, y = value)) + 
  geom_line() + 
  geom_point()
plot_ts_plotly = plotly::ggplotly(plot_ts)
plot_ts_plotly

```

## Timeseries from openEO Platform

Retrieving the point timeseries could also be done via openEO platform directly. Just add an `aggregate_spatial()` to the end of your process graph and feed it with a point (sf object). 

We're continuing to build on top of our last process graph.

```{r aggregate_spatial, eval = FALSE}
agg_spat = p$aggregate_spatial(data = temp_period, 
                               geometries = pixel, 
                               reducer = function(data, context){p$median(data)})
result2 = p$save_result(data = agg_spat, format = "netCDF")
```

Check the updated process graph
```{r result2, eval=FALSE}
toJSON(as(agg_spat, "Process"))
```

Run the process graph.

```{r compute_result2, eval=FALSE}
out_name2 = "r_ndvi_px_classroom_lps.nc"

a = Sys.time()
compute_result(result2,
               output_file = out_name2, 
               con = con)
b = Sys.time()-a
b
```

Analyze the result.

```{r analyse2}
ndvi_px = read_ncdf(out_name2)
ndvi_px_df = data.frame(value = ndvi_px %>% pull() %>% c() %>% as.vector(), 
                        dates = as.Date(st_get_dimension_values(ndvi_px, "t")))


plot_px = ggplot(ndvi_px_df, aes(x = dates, y = value)) + 
  geom_line() + 
  geom_point()
plot_px_plotly = plotly::ggplotly(plot_px)
plot_px_plotly

```
